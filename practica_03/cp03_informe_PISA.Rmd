---
title: "Práctica 3: modelos GAM"
author: "Gabriel Blanco García"
output: 
   html_document:
      toc: true
      toc_depth: 3
      number_sections: true
  
editor_options: 
  markdown: 
    wrap: 72
---
# Introuducción
## Motivación del trabajo
El objetivo es modelizar la relación entre la puntuación media de ciencias 
y el resto de variables, utilizando modelos de splines y GAM

## Qué es PISA 
Es un programa internacional para la evaluación de estudiantes, o por sus 
siglas en inglés, Programme for International Student Assessment. Lo realiza 
la OCDE a nivel mundial, y su objetivo no es evaluar a los estudiantes, sino 
valorar el sistema educativo al que pertenencen. No obstante, para este 
trabajo se emplea únicamente la calificación en ciencias de cada 
alumno para su respectivo país.

## Glosario de términos
Las variables clave y que se emplean en el análisis son las siguientes
- Overall: la nota media de ciencias.
- Interest: el interés del alumno por la ciencia
- Support: el apoyo a la investigación científica en el país.
- Income: la paridad de poder adquisitvio en dólares de 2005
- Health: índice de salud del país
- Education: índice de educación del país
- HDI: índice de desarollo humano, compuesto por los tres anteriores. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      fig.height = 7, fig.width = 10, fig.align = "center")
```

```{r paquetes}
library(tidyverse) # trata de datos
library(broom) # modelos en version tidy 
library(flextable) # tablas con formato 
library(kableExtra) # tablas con formato
library(reshape2)
library(janitor) # limpieza
library(skimr) # summary 

library(imputeTS) # imputar NA

library(rsample) # division de los datos
library(mgcv) # el modelo 
library(glmnet) # la regularizacion 
```


# Análisis exploratiorio 
```{r cargo los datos}
pisa <- read.csv("data/pisasci2006.csv")
pisa <- clean_names(pisa)
skim(pisa)
```
Eliminación de las variables que no son clave 

```{r}
pisa <- pisa %>% 
  select(-c("issues", "explain", "evidence"))
```

Tratamiento de los valores nulos: todas aquellas observaciones que tengan 
más de 3 valores nulos se eliminan, puesto que teniendo 7 variables, es preferible 
eliminar aquellas observaciones que tengan 4 valores nulos o más. Para el resto
de casos, se evalúa la distribución de dicha variable. Si no hay valores 
extremos, se imputa la media. Si por el contrario hay valores extremos, se 
imputa la mediana.

```{r quito NA}
pisa <- pisa %>% 
  mutate(total_na = rowSums(is.na(pisa))) %>% # suma por filas de los NA
  filter(total_na < 4) # me quedo solo con las de menos de 4 NA

head(pisa)

pisa <- pisa %>% 
  select(-c("total_na")) # quito esta columna que ya no me hace falta 
```
En total se eliminan 4 observaciones. Ahora para la imputacion, se representan
gráficamente las variables, con el fin de identificar qué variables tienen 
valors extremos. Se utilizan diagramas de caja y bigotes porque éstos
representan los valores extremos con puntos. En concreto, los boxplot utilizan
el criterio del rango intercuartílico. Esto es, caulquier valor que esté 
por encima del tercer cuartil más 1.5 veces el rango intercuartílico, o por 
debajo del primer caurtil menos 1.5 veces el rango intercuartílico, se considera
valor extremo. En un diagrama de caja y bigotes. la distancia de 1.5 veces el
rango intercuartílico viene representada por los "bigotes".  
Los diagramas se hacen en dos grupos, puesto que el segundo grupo de variables 
es de valores porcentuales, y si se representa con las primeras variables, la 
visualización es inservible

```{r visualizacion de outliers en dos grupos}
ggplot(stack(pisa[, 2:4]), aes(x = ind, y = values, fill = ind)) +
  geom_boxplot() 

ggplot(stack(pisa[, 5:8]), aes(x = ind, y = values, fill = ind)) +
  geom_boxplot() 
```

Como no hay variables con valores extremos, imputo la media de cada variable 
para sus valores NA.
```{r imputacion}
pisa <- na_mean(pisa)
sum(is.na(pisa))
```
La función `na_mean()` del paquete `imputeTS` recorre el dataframe, y sustituye
cada valor NA por la media de la variable de dicho valor. También se puede 
imputar la mediana, pero en este caso no es necesario.

## Visualizaciones

```{r}
library(GGally)

ggpairs(pisa, 
      columns = 2:8,
      ggplot2::aes(combo = "box"),
      combo = "box_no_facet", 
      discrete = "facetbar")
```
Todas las variables están medianamente correlacionadas con la nota de 
ciencias. Es llamativo que la variable interés muestre una correlación tal 
negativa con respecto a la nota media, algo que no cabría imaginarse a 
priori. 

A continuación se representan los gráficos de dispersión de todas
las variables en relación con la nota media. Se ajustan las nubes de 
puntos utilizando regresión lineal

```{r dispersiones lm}
pisa %>% 
  gather(key = "variable", value = "valor", 3:8) %>% 
  ggplot(aes(x = valor, y = overall)) +
    geom_point(color = "darkslategray3", alpha = 0.75) +
    geom_smooth(method = "lm",
                se = FALSE,
                color = "red3") +
    
    facet_wrap(~variable, ncol = 3, scales = "free") +
    theme_minimal()
```
Se puede observar que la regresiónn lineal no se ajusta demasiado bien, en
términos generales, a los datos. Probemos el mismo gráfico con un ajuste
mediante GAM




```{r dispersiones GAM}
pisa %>%
  gather(key = "variable", value = "valor", 3:8) %>% 
  ggplot(aes(x = valor, y = overall)) +
    geom_point(color = "darkslategray3", alpha = 0.75) +
    
    geom_smooth(method = "gam",
                se = FALSE,
                color = "red3") +
    
    facet_wrap(~variable, ncol = 3, scales = "free") +
    theme_minimal()
```
Parece claro que un modelo GAM resulta el adecuado para este problema, pese 
a haber variables que parecen presentar relación lineal.

# Modelos GAM 

Ya que todas las variables mostraban alta correlación, incluyo todas en el modelo. Utilizo splines suavizados en las variables que no muestran 
relacion lineal en los gráficos. Solo empleo el hdi, puesto que las otras
tres variables (health, income y education estan contenidas en hdi)

```{r}
modelo_inicial <- gam(overall~ s(interest) + support + hdi, data = pisa)
```

Planteo otro modelo con las variables de hdi por separado, y todas las variables
con splines. El motivo es que, aunque la relación sea lineal, el spline se 
suavizará para tomar forma de relacion lineal

```{r}
modelo_splines <- gam(overall ~ s(interest) + s(income) + s(edu) +
                           s(health) + s(support), data = pisa)
```



## Selección de nudos
Se crea una secuencia de valores para los nudos de cada spline, se ajustan ambos
modelos para cada número de nudos, y se evalúan las métricas de cada uno. 

```{r modelo inicial}
fold_id <- sample(1:10, 
                  size = length(pisa), 
                  replace = TRUE)

# La tabla con las metricas inicializadas en NA
tabla_de_ajustes <- tibble::tibble(
  nudos      = seq(1, 20, by = 1), 
  MSE        = NA,                   
  AIC        = NA
)

# Utilizando un bucle, se evalua el modelo para cada uno de los 
# totales de nudos
for (i in seq_along(tabla_de_ajustes$nudos)) {
  
 
  # Uso el modelo inicial, con unn solo spline y distintos nudos 
  fit <- gam(overall~ s(interest, k = tabla_de_ajustes$nudos[i]) + 
               support + hdi, 
             data = pisa) 
  tabla_de_ajustes$MSE[i] <- mean((pisa$overall - fit$fitted.values)^2)
  tabla_de_ajustes$AIC[i] <- fit$aic
  
}

# La tabla con formato
kable(tabla_de_ajustes, 
      caption = "Métricas con distintos nudos, primer modelo") %>% 
  kable_styling(bootstrap_options = "striped")
  
```
Los resultados muestran que a mayor numero de nudos, mejor ajuste del modelo. 
Sin embargo, desde el punto de vista predictivo, lo que se busca precisamente
es evitar ese sobreajuste, para que el modelo pueda generalizar bien
y tenga éxito al predecir sobre datos nuevos.
A continuación, se repite el proceso anterior de evaluación del modelo para 
distintos nudos, pero con el modelo secundario, con más splines. 


```{r}
fold_id <- sample(1:10, 
                  size = length(pisa), 
                  replace = TRUE)

# La tabla con las metricas inicializadas en NA
tabla_de_ajustes_2 <- tibble::tibble(
  nudos      = seq(1, 10, by = 1), 
  MSE        = NA,                   
  AIC        = NA
)

# Utilizando un bucle, se evalua el modelo para cada uno de los 
# totales de nudos 
for (i in seq_along(tabla_de_ajustes_2$nudos)) {
  
 
  # Uso el modelo con splines en todas las variables 
  fit <- gam(overall ~ s(interest, k = tabla_de_ajustes_2$nudos[i]) + 
                       s(income, k = tabla_de_ajustes_2$nudos[i]) + 
                          s(edu, k = tabla_de_ajustes_2$nudos[i]) +
                       s(health, k = tabla_de_ajustes_2$nudos[i]) + 
                       s(support, k = tabla_de_ajustes_2$nudos[i]), 
             data = pisa)
  
  tabla_de_ajustes_2$MSE[i] <- mean((pisa$overall - fit$fitted.values)^2)
  tabla_de_ajustes_2$AIC[i] <- fit$aic
  
}

kable(tabla_de_ajustes_2, 
      caption = "Métricas con distintos nudos, primer modelo") %>% 
  kable_styling(bootstrap_options = "striped")

```

De nuevo, es posible apreciar como a mayor numero de nudos, mejor ajuste del 
modelo. No obstante, en la tabla anterior se evalúaa un mismo numero de nudos 
para cada spline, cuando puede susceder que cada función de spline tenga un 
número óptimo de nudos distinto de las demás. 

## Visualicaciones de los modelos 

```{r}
modelo_inicial_5_nudos <- gam(overall~ s(interest, k = 5) + support + hdi, 
                              data = pisa)

modelo_inicial_10_nudos <- gam(overall~ s(interest, k = 10) + support + hdi, 
                              data = pisa)


modelo_secundario_5_nudos <- gam(overall ~ s(interest, k = 5) + 
                                           s(income, k = 5) + 
                                           s(edu, k = 5) +
                                           s(health, k = 5) + 
                                           s(support, k = 5), 
                                 data = pisa)

modelo_secundario_10_nudos <- gam(overall ~ s(interest, k = 10) + 
                                            s(income, k = 10) + 
                                            s(edu, k = 10) +
                                            s(health, k = 10) + 
                                            s(support, k = 10), 
                                 data = pisa)  



```

```{r}
# Modelo simple, un solo spline
par(mfrow = c(1,2))
plot(modelo_inicial_5_nudos, 
     residuals = TRUE, 
     pch = 1.2, 
     
     main = "Modelo con 5 nudos",
     shade = TRUE,
     shade.col = "cyan")

plot(modelo_inicial_10_nudos, 
     residuals = TRUE, 
     pch = 1.2, 
     
     main = "Modelo con 10 nudos",
     shade = TRUE,
     shade.col = "cyan")

```
Se puede apreciar claramente como a mayor numero de nudos, mayor ajuste del 
modelo a los datos. Otro argumento a tener en cuenta es `sp =`, con el cual 
se puede determinar el factor de suavizado de cada nudo. Toma valores entre 
0 y 1, siendo 1 el caso más extremo en el que la función de cada nudo 
es totalmente plana.

```{r}
# Ejemplo sp 
modelo_sp_bajo <- gam(overall~ s(interest, k = 10) + support + hdi, 
                              data = pisa, sp = 0.00001)
modelo_sp_alto <- gam(overall~ s(interest, k = 10) + support + hdi, 
                              data = pisa, sp = 1)

par(mfrow = c(1,2))
plot(modelo_sp_bajo, 
     residuals = TRUE, 
     pch = 1.2, 
     
     main = "sp = 0.00001",
     shade = TRUE,
     shade.col = "cyan")

plot(modelo_sp_alto, 
     residuals = TRUE, 
     pch = 1.2, 
     
     main = "sp = 1",
     shade = TRUE,
     shade.col = "cyan")
```

```{r}
# Modelo secundario, con 3 splines

plot(modelo_secundario_5_nudos, 
     residuals = TRUE, 
     pch = 1.2, 
     pages = 1, 
     all.terms = TRUE, 
     main = "Modelo con 5 nudos",
     shade = TRUE,
     shade.col = "cyan")

plot(modelo_secundario_10_nudos, 
     residuals = TRUE, 
     pch = 1.2, 
     pages = 1, 
     all.terms = TRUE, 
     main = "Modelo con 10 nudos",
     shade = TRUE,
     shade.col = "cyan")
```
Las visualizaciones revelan de manera clara como a mayor numero de nudos, mejor 
ajuste, llegnado al extremo de que para las variables income y health prácticamente
ningúnn punto queda fuera del intervalo de confianza al emplear 20 nudos. El 
modelo por tanto ajusta muy bien, pero probablemente est? sobreajustado, algo 
que es un grave problema a la hora de predecir con el modelo. 


Estos son los grados de libertad optimos para cada spline del modelo.

## Comparativa de modelos 

```{r}
# Creo la funcion para sacar una tabla con estadisticos
tablas <- function(modelo) {
output <- width(flextable(glance(modelo)), width = 1.25)
output
}

tablas(modelo_inicial_5_nudos)
tablas(modelo_inicial_10_nudos)
tablas(modelo_secundario_5_nudos)
tablas(modelo_secundario_10_nudos)


```
El mejor de los anteriores modelos es el modelo secundario con 10 nudos, puesto
que es el que presenta menor AIC. Si se utiliza el criterio Bayesiano, los 
resultados son similares. 
¿Cual sería el resultado con  otros grados de libertad? ¿Qué grados de libertad
proucen el mejor modelo?

## Selección de grados de libertad

Los grados de libertad que R selecciona para variable se pueden 
extraer de la siguiente mantera 

```{r}
# Defino una funcion que extraiga los grados de libertad de cada spline
extrae_grados_libertad <- function(variable) {
  
  grados <- smooth.spline(x = variable, # vble. predictora como parametro
                          y = pisa$overall, # vble. dependiente fija
                          cv = TRUE)$df # cálculo mediante cross validation
  grados
}

# Creo una tabla para recoger los datos de los grados de libertad 
tabla_grados_libtertad <- tibble(
  Variable = names(pisa[, 3:7]), # columna con los nombres de las vbles.
  "Grados de libertad" = sapply(pisa[, 3:7], # variables predictoras 
                              extrae_grados_libertad) # aplica la funcion
)

# Resultado
kable(tabla_grados_libtertad, 
      caption = "Tabla de grados de libertad para cada spline") %>% 
  kable_styling(bootstrap_options = "striped")

```

Desafortunadamente, no he encontrado ninguna función
en ningún paquete que permita seleecionar de manera manual cual es el número 
de grados de libertad del modelo gam en conjunto. El argumento `df` de 
`smooth.splines()` permite hacerlo, pero dicha función solo admite una variable
predictora. Con todo, el modelo que mejor parece ajustarse
a los datos es el siguiente 

$overall\: =\: s(interest)\: +\: s(support)\: +\: s(income)\: +\: s(health)\: +\: s(edu)$


utilizando 10 nudos en cada spline. Nuevamente, conviene recordar que estos
datos son de caracter descriptivo, puesto que es muy porbable que el modelo esté
sobreajustado, y sea absolutamente nulo en términos predictivos.



