---
title: "NBA: modelos predictivos para el salario de los jugadores"
author: "Gabriel Blanco García"
output: 
   html_document:
      toc: true
      toc_depth: 3
      number_sections: true
  
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.height = 7, fig.width = 10, fig.align = "center")
```

# Motivación del trabajo

La motivación de este trabajo es la elaboración de un modelo predictivo que permita estimar, con la mayor precisión posible, los salarios anuales de jugadores de la NBA. Para ello, se utiliza un dataset con distitnas variables relativas a una serie de jugadores de la NBA, y siguiendo las etapas típicas de un proyecto de predicción, se intenta implementar el mejor modelo predictivo.

# Etapas del proceso

Las fases de la investigación son las estudiadas en clase y se asemejan al siguiente diagrama:\
![](data/proceso a seguir.JPG)

En primer lugar, se realiza un análisis exploratorio de los datos, en este caso poniendo primro el foco en las variables cuantitativas, y más tarde en las categóricas.

Después, en la fase de ingeniería de variables, se modifican algunas de las variables existentes con el fin de transformar los datos disponibles y hacer que encajen mejor en los modelos.

Posteriormente, se plantean una serie de modelos, basados en parte en el análisis exploratorio así como en algoritmos de selección de variables.

Tras el planteamiento de los primeros modelos, se pasa a evaluar la precision de éstos, y se elige aquel que tenga mejor capacidad predictiva. Ese mismo modelo se evalúa de nuevo, y se plantea nuevamente ingeniería de variables con el objetivo de tratar de refinar el modelo, y mejorar la predicción.

Finalmente, se evalua el modelo final sobre datos nuevos y se valoran sus métricas.

## Contrastes de hipótesis.

Es importante recordar que para que los modelos funcionen correctamente, es necesario verificar que se cumplen una serie de supuestos, tales como:

-   Normalidad

-   Homocedasticidad

-   Ausencia de multicolinealidad

-   Linealidad

No obstante, estas comprobaciones son propias de modelos descriptivos, y el caso que ocupa a este trabajo es el desarrollo de un modelo predictivo. Por esta razón, no se llevan a cabo este tipo de contrastes, ni se pone el foco en la capacidad explicativa del modelo, sino que se valoran sus capacidades predictivas.

# Glosario de términos.

A continuación se incluye la descripción de cada una de las variables del dataset, utilizando la materia de clase y el apartado de estadísticas de la página web de la NBA.

-   Player: nombre y apellidos del jugador.
-   Salary: salario anual, la variable dependiente y la que se busca predecir, medido en dólares.
-   NBA_Country: nacionalidad del jugador.
-   NBA_DraftNumber: el número de draft del jugador, es decir, en qué puesto entró en la NBA.
-   Age: edad del jugador.
-   Tm: nombre de su equipo.
-   G: partidos que ha jugado en la temporada regular de 82 partidos.
-   MP: minutos jugados en toda la temporada.
-   PER: medida de eficiencia del jugador estandarizada sobre la media de la liga (15).
-   TS%: porcentaje de aciertos de cualquier tipo de tiro.
-   3PAr: porcentaje de triples que el jugador tira respecto a sus tiros de campo totales.
-   FTr: porcentaje de tiros libres tirados respecto a sus tiros de campo totales.
-   ORB%: porcentaje de rebotes ofensivos que el jugador consigue.
-   DRB%: porcentaje de rebotes defensivos que el jugador consigue.
-   TRB%: porcentaje de rebotes que el jugador consigue, en general.
-   AST%: porcentaje de tiros de compañeros que el jugador ha asistido.
-   STL%: porcentaje de robos de un jugador respecto a los robos totales de su equipo.
-   BLK%: porcentaje de tapones del jugador respecto a los de su equipo.
-   TOV%: porcentaje de jugadas que acaban en turnover (recuperación).
-   USG%: porcentaje de uso, las jugadas en las que el jugador interviene respecto al total de jugadas de su equipo.
-   OWS: estimacion de las victorias que se deben a la habilidad ofensiva del jugador.
-   DWS: estimacion de las victorias que se deben a la habilidad defensiva del jugador.
-   WS: estimación de las victorias que se deben a la habilidad general del jugador.
-   WS/48: normalicacion de WS por cada 48 minutos. Por cada 48 minutos de juego del jugador, cuantas victorias genera.
-   OBPM: estimación de los puntos ofensivos de cada 100 posesiones en los cuales el jugador ha contribuido más que la media de la liga, traducido a la media del equipo.
-   DBPM: estimación de los puntos defensivos de cada 100 posesiones en los cuales el jugador ha contribuido más que la media de la liga, traducido a la media del equipo.
-   BPM: estimación de los puntos generales de cada 100 posesiones en los cuales el jugador ha contribuido más que la media de la liga, traducido a la media del equipo.
-   VORP: mide el rendimiento de un jugador contra el que daria un "jugador medio".

```{r paquetes}
library(tidyverse) # tratamiento de datos y visualizaciones
library(rsample) # division de los datos 
library(janitor) # limpieza de nombres 
library(skimr) # summary mejorado

library(Hmisc) # correlaciones 
library(plotly) # visualizaciones interactivas
library(ggcorrplot) # correlogramas

library(car) # seleccion de modelo 
library(leaps) # seleccion de modelo
library(glmnet) # regularizacion de modelos

```

Como ya se ha comentado, la primera parte consiste en un análisis exploratorio de los datos.

```{r carga de los datos}

# Importacion de los datos
nba <- read.csv("./data/nba.csv")

# Dimensiones del dataframe
dim(nba) # 458 observaciones, 28 variables 

glimpse(nba) # vistazo rapido a las variables
```

El dataset consta de 458 observaciones, con 28 variables de distinto formato. Tres de las variables son categóricas, algo a tener en cuenta si se quieren utilizar para las predicciones, y el resto de variables son numéricas. Antes de continuar, se evalúa la presencia de valores no disponibles, algo que puede entorpecer el resto de procesos. También se comprueba la ausencia de valores duplicados, pese a que el enunciado indica que ya se han elimiando, solo para comrpobar que no ha habido problemas en la carga de los datos.

# Limpieza de datos

### Nombres, valores NA y duplicados

```{r limpieza de nombres}
nba <- nba %>% 
  clean_names()
```

```{r Resumen NAs y duplicados}
skim(nba)
```

Se encuentran un total de 8 valores no disponibles, correspondientes a las observaciones de Tyler Lydon y Trey McKinney-Jones. Dada la cantidad de datos disponibles, se opta por la eliminación de estas dos observaciones, puesto que el efecto de su ausencia no tiene repercusión notable. También se encuentran doss valores duplicados, puesto que la cuenta de unique es 483, y se disponen de 485. También se eliminan

```{r eliminacion NA y duplicados}
nba <- nba %>% 
  distinct(player, .keep_all = TRUE) %>%  # quita duplicados
  drop_na()  # quita na

# Verifico el resultado 
skim(nba)
```

# Análisis exploratorio

## Correlaciones

Se examinan las correlaciones de las variables cuantitativas, con el fin de tener una primera idea de qué puede influir en el salario de los jugadores. No obstante, es necesario recordar que correlación no implica causalidad.

```{r todas las correlaciones, fig.height = 10, fig.width = 10, fig.align = "center"}
nba_numericas <- nba %>% 
  select(-c(1, 3, 6))  # creo un nuevo dataframe que cotniene solo
# las variables numéricas

rh <- rcorr(as.matrix(nba_numericas), # solo las cuantitativas
            type = "pearson")


# Correlograma 
ggcorrplot(rh$r, 
           method = 'square', 
           type = 'lower', # crea el correlograma de manera diagonal
           lab = TRUE) + 
  
  # Títulos y aspectos visuales
  ggtitle("Correlograma") +
  theme_bw() +
  theme_minimal() +
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x = element_text(angle =  90)) # rotacion del  
  # texto del eje x para facilitar su lectura

```

No hay variables que estén fuertemente correlacionadas con el salario. No obstante, para el primer modelo se incluirán aquellas que tienen más de un 0.25 de correlación, positiva o negativa. Estas variables son el número del draft, Win Share (WS), el valor de reemplazo (VORP), los minutos jugados (MP) y la edad del jugador (Age). Se excluye la salida de la matriz, porque es una matriz de dimensiones 25 x 25. No obstante, se puede acceder a los datos con `rh$r`.

Se puede apreciar que existen distintas variables que presentan alta correlacion entre ellas. Este fenómeno se da en aquellas que están relacionadas, como por ejemplo el porcentaje de rebotes ofensivos, defensivos y totales. A continuación se muestra un correlograma que incluye exclusivamente estas variables.

```{r correlaciones mas fuertes entre si, fig.height = 10, fig.width = 10, fig.align = "center"}

correlaciones_fuertes <- nba_numericas %>% 
  select(orb, drb, trb, dws, ows, ws, 
         per, ws_48, obpm, bpm, vorp) # selecciono las variables del 
# dataset

# Calculo las correlaciones
rh_fuertes <- rcorr(as.matrix(correlaciones_fuertes, 
                             type = "pearson"))
    
# Correlograma
ggcorrplot(rh_fuertes$r, 
           method = 'square', 
           type = 'lower', 
           lab = TRUE) + # añade los valores numéricos
  
  # Titulos y aspectos visuales 
  ggtitle("Correlaciones fuertes") +
  theme_bw() +
  theme_minimal() +
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x = element_text(angle =  90)) # rotación del  
  # texto del eje x para facilitar su lectura

```

## Gráficos de dispersión

A continuación se representan gráficamente todas las variables numéricas en forma de gráfico de dispersión, manteniendo el salario siempre en el eje Y. Se añade la linea de regresión lineal a modo de indicador de las relaciones que existen entre las variables y el salario, primero con el salrio en dólares y después en logaritmos.

```{r fig.height = 12, fig.width = 7, fig.align = "center"}
nba_numericas %>% 
  gather("id", "value", 2:25) %>% 
  ggplot(aes(y = salary, 
                x = value)) +
  geom_point(color = "aquamarine3") +
  geom_smooth(method = "lm", 
              se = FALSE, 
              color = "red") +
  
  facet_wrap(~id,
             ncol = 3,
             scales = "free_x")
```

No parece existir ninguna tendencia clara. A continuación, visualización en logaritmos

```{r fig.height = 12, fig.width = 7, fig.align = "center"}
nba_numericas %>% 
  gather("id", "value", 2:25) %>% 
  ggplot(aes(y = log(salary), 
                x = value)) +
  geom_point(color = "aquamarine3") +
  geom_smooth(method = "lm", 
              se = FALSE, 
              color = "red") +
  
  facet_wrap(~id,
             ncol = 3,
             scales = "free_x")
```

En principio, no parece haber grupos diferenciados en cada variable, y para mismos niveles de cada variable, el salario varía mucho. No obstante, la variable que mayor relación parece presentar con el salario es el número del draft. Se aprecia una tendencia negativa, a medida que el número del draft aumenta, el salario anual se reduce. Aún así, para esta variable también existe mucha dispersión en términos de salario para cada variable. También existen valores extremos que fuerzan la pendiente de la regresión en una dirección.

## Funciones de densidad

```{r fig.height = 12, fig.width = 7, fig.align = "center"}
nba_numericas %>% 
  gather("id", "value", 2:25) %>% 
  ggplot(aes(x = value)) +
  geom_density(fill = "aquamarine3") +
  
  
  facet_wrap(~id,
             ncol = 3,
             scales = "free")
```

La mayoría de variables presenta una distribución estrecha, con poca varianza. Sin embargo, variables como el número del draft o los minutos jugados parecen agruparse en torno a dos puntos diferenciados. Puede ser interesante estudiar estas características y decidir si es conveniente hacer agrupaciones para variables, especialmente para el grupo de draft.

## Variables cuantitativas

Se excluye del análisis a la variable de nombre del jugador, porque es coherente pensar que no es útil a la hora de determinar el salario.

### Equipo

El siguiente gráfico muestra el salario medio por equipos

```{r equipos salario medio y mediano}
ggplot(nba, 
       aes(x = tm), 
       ) +
  geom_col(aes(y = mean(salary)),
           fill = "aquamarine3") + # media en verde
  
  geom_col(aes(y = median(salary)), 
           fill = "lightblue") + #  mediana en azul
  
  coord_flip() + # giro el grafico
  theme_minimal() + 
  labs(title = "Salario medio y mediano por equipos",
       x = "Equipo",
       y = "Salario medio y mediano")
```

Tal como se puede observar, el salario medio por equipos es bastante similar. El único valor que destaca claramente es el de "TOT", que hace referencia a jugadores que en la misma temporada han cambiado de equipo. En color azul se representa la mediana, puesto que es robusta a valores extremos. El valor es igualmente similar por equipos.

```{r jugadores con varios equipos}
nba %>% 
  filter(tm == "TOT") %>% 
  arrange(desc(salary)) %>% 
  head()

```

Seria interesante construir una nueva variable, que contraste si el jugador ha jugado en varios equipos o no.

### Nacionalidad

Visualizacion de los jugadores por su nacionalidad

```{r Nacionalidad }

ggplot(nba, 
       aes(x = nba_country), 
       ) +
  geom_bar(fill = "aquamarine3", 
       color = "black") +
  coord_flip() +
  theme_minimal() + 
  labs(title = "Nacionalidad de los jugadores",
       y = "Nº de jugadores",
       x = "Nacionalidad")

```

La inmnesa mayoria de los jugadores son de nacionalidad estadounidense. A continuacion una visualicación que excluye a USA, para ver bien los jugadores en el resto

```{r sin USA}
nba %>% 
  filter(nba_country != "USA") %>% # el filtro para paises                                               # distintos a usa
  
  ggplot(aes(x = nba_country)) +
  geom_bar(fill = "aquamarine3", 
           color = "black") +
  coord_flip() + # giro el grafico 
  theme_minimal() + 
  labs(title = "Nacionalidad de los jugadores (excluida USA)",
       y = "Nº de jugadores",
       x = "Nacionalidad")
```

# Ingeniería de variables inicial

En base a las variables categóricas examinadas, en este apartado se plantean una serie de transformaciones y creaciones de variables, para extender el análisis de datos, y para incluirlas en el modelo si pudiese resultar interesante.

### Equipo

El gráfico de salario medio y mediano para cada equipo revela que la categoría "TOT", la cual recoge a los jugadores que han jugadoen varios equipos en la misma temporada, tiene valores muy superiores al resto. Puesto que quizá sea interesante introducir una variable que recoja esta diferencia en el modelo, se procede a su creación, mediante "string encoding"

```{r Feat Eng equipos}
nba <- nba %>% mutate(
  varios_equipos = case_when(tm == "TOT" ~ "Varios equipos",
                            tm != "TOT" ~ "Un solo equipo"
  )
)
# Se crea la variable "variosEquipos" que tomará el valor 
# "Varios equipos" si el jugador ha jugado en varios equipos, 
# y "Un solo equipo en caso contrario"



# Paso a factor
nba$varios_equipos <- as.factor(nba$varios_equipos)
```

Una vez creada la variable, se procede a examinar el comportamiento del salario para cada grupo

```{r Feat Eng equipos grafico}
library(plotly)

ggplotly( # ggplotly transforma el gráfico en interactivo
ggplot(nba, aes(x = varios_equipos, 
                y = salary, 
                fill = varios_equipos)) +
  geom_boxplot() +
  labs(title = "Un equipo vs. varios",
       x = NULL, 
       y = "Salario",
       fill = NULL) + # titulo de la leyenda
  theme_minimal() +
  theme(axis.text.x = element_blank()) # quita las x ticks
)
```

Pese a lo constatado al analizar la categoría de varios equipos contra los equipos de manera individual, el grafico de caja y bigotes muestra que, al comparar ambos grupos, no existen grandes diferencias. El salario mediano es practicamente el mismo, aunque la distribucón es algo más pequeña en el grupo de varios equipos. Hay que tener en cuenta que este grupo tiene muchos menos individuos que el grupo de un solo equipo.

```{r test igualdad de medias}
t.test(nba$salary ~ nba$varios_equipos)
```

El t-test, que establece como hipótesis nula la igualdad de media entre grupos, devuelve un p.valor que no permite rechazar la igualdad, aunque por poco. El salario medio de los dos grupos es estadísticamente igual.

No obstante, a continuación se crea una nueva variable "dummy" utilizando la técnica de "one hot encoding" con el fin de poder incluir esta variable en los modelos, para ver su efecto.

```{r Feat Eng equipos dummy}

nba <- nba %>% 
  mutate(varios_equipos_dummy = ifelse(tm == "TOT", 1, 0))
# Toma el valor 1 si el jugador ha judado en mas de un equipo
```

### Nacionalidad

Igual que para el caso del equipo, se crea una nueva variable que codifique si el jugador es estadounidense o no. El procedimiento es el mismo.

```{r Feat Eng nacionalidad}
# Creacion de la nueva columna
nba <- nba %>% 
  mutate(nacionalidad = 
           case_when(nba_country == "USA" ~ "USA",
                     nba_country != "USA"~ "NotUSA"))


# Conversión a factor
nba$nacionalidad <- as.factor(nba$nacionalidad)

 

ggplotly( # ggplotly transforma el gráfico en interactivo

  ggplot(nba, aes(x = nacionalidad, 
                y = salary, 
                fill = nacionalidad)) +
    
    geom_boxplot() +
    
    labs(title = "Salarios de estadounidenses vs. no estadounidenses",
       x = NULL, 
       y = "Salario",
       fill = NULL) + # titulo de la leyenda
    
    theme_minimal() +
    theme(axis.text.x = element_blank()) # quita las x ticks
)
```

Igual que para el caso de los equipos, las distribuciones son casi iguales

```{r contraste nacionalidad}
t.test(nba$salary ~ nba$nacionalidad)
```

No se rechaza la igualdad de medias. Igualmente, se genera la variable "dummy" de cara a incluirla en los modelos.

```{r Feat Eng usa Dummy}
nba <- nba %>% 
  mutate(nacionalidad_dummy = ifelse(nacionalidad == "USA", 1, 0))
# Toma el valor 1 si el jugador es de USA
```

Antes de continuar, es necesario actualizar los datos del dataframe de variables numéricas, para que contenga las variables dummy creadas

```{r}
nba_numericas <- nba %>% 
  select(-c("player", "nba_country", "tm", # las tres categoricas
                                           # originales
                 "varios_equipos", "nacionalidad"))  # las dos                                                          # creadas con 
                                                     # string 
                                                     # encoding 
```

## VIF

Utilizo el factor de inflacion de la varianza para tratar de detectar si hay problemas de multicolinealidad entre las variables

```{r}
modelo_vif <- lm(log(salary) ~ ., data = nba_numericas)
valores_vif <- car::vif(modelo_vif)

barplot(valores_vif,
        main = "VIF por predictores",
        horiz = TRUE, 
        col = "springgreen")
abline(v = 5, lwd = 3, lty = 2, col = "red") # linea indicadora de problemas de VIF
```

```{r}
kableExtra::kable(valores_vif)
```

Valores superiores a 5 pueden ser indicadores de problemas de multicolinealidad. El dataset presenta numerosas variables susceptibles de estos problemas, tal como indican sus elevados valores de VIF

# Modelos iniciales

## Selección de modelos: validación cruzada y elastic net

La elección del modelo se hace con cross validation La elección del hiperparámetro de regulación del modelo se hace con cross validation

En primer lugar, es necesario dividir los datos entre train y test

```{r Division de los datos}
set.seed(123) # asegura la reproductibilidad

nba_split <- initial_split(nba_numericas, 
                           prop = 0.7, # 70% train, 30% test
                           strata = salary) # variable dependiente

# Sobre este trozo se estiman los parametros, es decir, se entrena # el  modelo
nba_train <- training(nba_split) 

# Sobre este trozo se predice, se testea, se prueba la eficacia del 
# modelo, con datos que no han sido utilziados para 
# el entrenamiento

nba_test <- testing(nba_split) 
```

Posteriormente, es necesario distinguir las variables predictoras de la variable dependiente, tanto en el tramo de entrenamiento como en el tramo de validación. La variable dependiente que se emplea es el salario de los jugadores en forma de logaritmo. Como predictores, se incluyen inicialmente todas las variables del dataset.

```{r}
# Sobre conjunto train:

# Matriz de predictores 
nba_train_x <- model.matrix(salary ~ ., nba_train)[, -1] 

# Vector de la variable dependiente (logaritmo del salario)
nba_train_y <- log(nba_train$salary) 


# Sobre el conjunto de test:

# Matriz de predictores
nba_test_x <- model.matrix(salary ~ ., nba_test)[, -1]

# Vector de la variable dependiente (logaritmo del salario)
nba_test_y <- log(nba_test$salary) # variable dependiente (en logaritmo)

```

A continuación, es necesario decidir cuales son los hiperparámetros alpha y lambda del modelo elastic net. Para decicidrlo, se utiliza validación cruzada y se estiman difernetes modelos, con diferentes niveles de alpha. Finalmente, se elegirá aquel alpha que origine el menor error cuadrático medio en el modelo, y ese será el modelo que se empleará para predecir el salario, utilizando los datos nuevos del conjunto de validación.

```{r creacion de la tabla}
# Creo una tabla sobre la que se van a guardar los distintos datos 
# relativos a los modelos estimados con cada nivel de alpha

# Para que todos los cv tengan las mismas muestras con las que compararse
fold_id <- sample(1:10, 
                  size = length(nba_train_y), 
                  replace = TRUE)

# La tabla con las metricas inicializadas en NA
tabla_de_ajustes <- tibble::tibble(
  alpha      = seq(0, 1, by = 0.05), # 21 niveles distintos de alpha. 
  mse_min    = NA,                   # se evalua el modelo con alpha de
  mse_1se    = NA,                   # 0, 0.05, 0.1, 0.15...
  lambda_min = NA,
  lambda_1se = NA 
)

# Utilizando un bucle, se evalua el modelo para cada uno de los 
# niveles de alpha
for (i in seq_along(tabla_de_ajustes$alpha)) {
  
  # Se utiliza validacion cruzada ("cv.glmnet" = Cross-validation for
  # glmnet, de regularizacion elastic net para modelos glm)
  
  fit <- cv.glmnet(nba_train_x, # predictores
                   nba_train_y, # variable dependiente
                   alpha = tabla_de_ajustes$alpha[i], # asigna a alpha 
                                                      # cada uno de los 
                                                      # valores de la
                                                      # tabla
                   foldid = fold_id)

  
  
  # Extración de las medidas de cada estimacion[i] y almacenaje 
  # en las correspondientes columnas de la tabla de ajustes.
  
  # cvm contiene el error medio validado de maner cruzada 
    # dentro de cvm, lambda.min contiene el valor de lambda 
    # que origina el minimo error cuadratico medio, y lambda.1se aquel       # que origina  el error medio + una desviacion típica
  tabla_de_ajustes$mse_min[i]    <- fit$cvm[fit$lambda == fit$lambda.min]
  tabla_de_ajustes$mse_1se[i]    <- fit$cvm[fit$lambda == fit$lambda.1se]
  tabla_de_ajustes$lambda_min[i] <- fit$lambda.min
  tabla_de_ajustes$lambda_1se[i] <- fit$lambda.1se
}

# Resultado 

kableExtra::kable(tabla_de_ajustes)
```

A continuación se representa gráficamente el error medio, junto con un intervalo de más menos una desviación típica, para cada nivel de alpha

```{r}
tabla_de_ajustes %>%
  # Calculo de la desviacion tipica mediante la diferencia de los valores
  # extraidos del modelo
  mutate(se = mse_1se - mse_min) %>%
  
  # Grafico de linea, error cuadratico minimo en funcion de alpha
  ggplot(aes(alpha, mse_min)) +
  geom_line(size = 1.5, color = "red") +
  
  # Función para graficar el intervalo
  geom_ribbon(aes(ymax = mse_min + se, # limite superior del intervalo 
                  ymin = mse_min - se), # limite inferior del intervalo
              alpha = .25) +
  
  labs(title = "Error medio cuadrado minimo ± una desviación típica",
       x = "Nivel de alpha",
       y = "Mínimo error cuadrático medio") +
  theme_minimal()
```

El gráfico desvela que el menor mínimo error cuadrático medio se consigue con niveles de alpha cercanos a uno. No obstante, para asegurar el resultado, filtro la tabla

```{r}
tabla_de_ajustes %>%
  filter(mse_min == min(mse_min))
```

Efectivamente, el nivel de alpha que minimiza el mínimo error cuadrático medio es 1, y el valor del hiperparámetro lambda es 0.07. Estos son los valores que se utilizan en el modelo para predecir.

## Predicciones

Una vez que se ha seleccionado el modelo, se pasa a validarlo sobre el conjunto de test, para ver como funciona con datos nuevos. Nuevamente, se utiliza validación cruzada

```{r mejor modelo}
mejor_modelo <- cv.glmnet(nba_train_x, nba_train_y, alpha = 1.0)
min(mejor_modelo$cvm) # error cuadrático medio validado de manera 
# cruzada
```

```{r prediccion}
prediccion <- predict(mejor_modelo, 
                      s = mejor_modelo$lambda.min, 
                      # el argumento "s"  determina el nivel
                      # del hiperparámetro lambda
                      nba_test_x)

mean((nba_test_y - prediccion)^2) 
# error cuadrado medio: real menos estimado, diferencia al cuadrado
                              

sd((nba_test_y - prediccion)^2) # desviación del error cuadrático 
```

# Ingeniería de variables II

En un intento de mejorar los resultados del modelo, se vuelven a plantear transformaciones de las variables.

### Draft por grupos

A continuación se secciona la variable draft en 6 grupos de unas 10 posiciones en cada grupo, con el objetivo de ver su influencia en el salario, y como puede afectar al modelo introducir una variable que contraste la pertenencia a cada grupo.

```{r grupos de draft}
# Primero string encoding
# Se crea una nueva variable para cada intervalo de 10 drafteados
nba <- nba %>% 
  mutate(draft_group = 
                 case_when(
                   nba_draft_number >= 1 & 
                     nba_draft_number <= 10 ~ "[1-10]",
                   
                   nba_draft_number >= 11 & 
                     nba_draft_number <= 20 ~ "[11-20]",
                   
                   nba_draft_number >= 21 & 
                     nba_draft_number <= 30 ~ "[21-30]",
                   
                   nba_draft_number >= 31 & 
                     nba_draft_number <= 40 ~ "[31-40]",
                   
                   nba_draft_number >= 41 & 
                     nba_draft_number <= 50 ~ "[41-50]",
                   
                   nba_draft_number >= 51 ~ "[51-70]"))

# paso a factor
nba$draft_group <- as.factor(nba$draft_group)

# Grafico respecto a grupos
ggplotly(
  
  ggplot(nba, 
         aes(x = draft_group, y = salary, fill = draft_group)) +
    
    geom_boxplot() +
    scale_y_log10() + # salario a logaritmo
    
    labs(title = "Salario vs. draft",
         y = "Salario", 
         x = "Grupo de draft",
         fill = NULL) +
    theme_minimal()
  ) 

# Diagramas de violin 
ggplotly(
  ggplot(nba, 
         aes(x = draft_group, y = salary, fill = draft_group)) +
    
    geom_violin() +
    scale_y_log10() +
    
    labs(title = "Salario vs. draft",
         y = "Salario", 
         x = "Grupo de draft",
         fill = NULL) +
    theme_minimal() 
) 
```

Existe una tendencia decreciente en los salarios medios y medianos a media que el grupo de draft es más alto, es decir, los que se han drafteado más tarde. No obstante, los salarios máximos no varían especialmente, y los mínimos bajan, aunque no es una tendencia constante. Los diagramas de violines muestran como el salario es mucho más disperso en el último grupo.

A continuación se genera la variable dummy para la pertenencia al grupo con salario más alto, el de los 10 primeros drafteados, para ver si el pertenecer a dicho grupo puede afectar a la capacidad predictiva del modelo

```{r draftDummy}

nba <- nba %>% 
  mutate(draft_dummy = ifelse(draft_group == "[1-10]", 1, 0))
```

### Minutos jugados

La variable mp recoge cuantos minutos ha jugado cada jugador a lo largo de la temporada. Examinando los datos, podemos ver que existen jugadores que han jugado menos de 82 minutos en la temporada, lo que equivaldría a jugar un minuto por partido.

```{r minutos jugados}
# Listado de los de menos de 82
nba %>% 
  filter(mp < 82) %>% 
  select(player, salary, mp) %>% 
  arrange(desc(salary)) %>% 
  head(10)

```

Vemos como pese ha haber jugado tan poco, los salarios son abultados. Teniendo en cuenta que esta variable pertenece al modelo, es posible que estos datos estén dificultando el ajuste. En este contexto, se crea una variable que analice el salario por minutos jugados, con el fin de tener un criterio comparativo.

```{r salario por minuto}

nba <- nba %>% mutate(
  salario_por_minuto = salary / mp
)

mean(nba$salario_por_minuto) # 33911.81 de media 
summary(nba$salario_por_minuto) # el maximo es muy abultado 
```

Con esta variable, se vuelve a filtrar el dataset. El filtro incluye aquellos jugadores cuyo **salario por minuto** es tres veces superior a la media del salario por minuto del dataset

```{r filtro salario por minuto}
nba %>% 
  filter(salario_por_minuto > (3*sd(salario_por_minuto))) %>% 
  select(player, salary, salario_por_minuto, mp) %>% 
  arrange(desc(salario_por_minuto))

# Recojo estos nombres 
nombres_outlier <- c("Gordon Hayward", 
                    "Mindaugas Kuzminskas", 
                    "Luol Deng",
                    "Josh McRoberts")

```

Con los nombres de esos jugadores, se filtra el dataset original, para eliminarlos.

```{r eliminacion de los jugadores}
nba <- nba[!nba$player %in% nombres_outlier, ] 
# seleccion de todos los que NO son. 

# La operacion de eliminar las filas por nombre de jugador no la 
# puedo hacer sobre nba_numericas, porque le falta la columna de 
# jugadores.

# Vuevlo a hacer la seleccion de las variable numericas, incluyendo # las dummy

nba_numericas <- nba %>% 
  select(-c("player", "nba_country", "tm", # las tres categoricas
                                           # originales
                 # Las tres creadas con string encoding            
                 "varios_equipos", "nacionalidad", "draft_group",
            "salario_por_minuto") # esta tampoco interesa
         )  

dim(nba_numericas) # me quedo con 477 observaciones y 28 variables
```

# Evaluación final del modelo

Una vez que se ha creado la nueva variable del draft y que se han eliminado algunos valores extremos, para lo cual hay que volver a dividir los datos y repetir el proceso anterior, incluida la particion del dataset. El codigo se comenta menos porque el proceso es el mismo

```{r Division de los datos 2}
set.seed(123) # asegura la reproductibilidad

nba_split_2 <- initial_split(nba_numericas, 
                           prop = 0.7, # 70% train, 30% test
                           strata = salary) # variable dependiente
nba_train_2 <- training(nba_split_2) 
nba_test_2 <- testing(nba_split_2) 
```

```{r}
nba_train_x_2 <- model.matrix(salary ~ ., nba_train_2)[, -1] # ahora 
# contiene las variables nuevas 

# Vector de la variable dependiente (logaritmo del salario)
nba_train_y_2 <- log(nba_train_2$salary) 

nba_test_x_2 <- model.matrix(salary ~ ., nba_test_2)[, -1]
nba_test_y_2 <- log(nba_test_2$salary) 
```

Decision de los hiperparámetros

```{r creacion de la tabla 2}

fold_id <- sample(1:10, 
                  size = length(nba_train_y_2), 
                  replace = TRUE)

# La tabla con las metricas inicializadas en NA
tabla_de_ajustes_2 <- tibble::tibble(
  alpha      = seq(0, 1, by = 0.05), 
  mse_min    = NA,                   
  mse_1se    = NA,              
  lambda_min = NA,
  lambda_1se = NA 
)

# Utilizando un bucle, se evalua el modelo para cada uno de los 
# niveles de alpha
for (i in seq_along(tabla_de_ajustes_2$alpha)) {
  
  # Se utiliza validacion cruzada ("cv.glmnet" = Cross-validation for
  # glmnet, de regularizacion elastic net para modelos glm)
  
  fit <- cv.glmnet(nba_train_x_2, # predictores
                   nba_train_y_2, # variable dependiente
                   alpha = tabla_de_ajustes_2$alpha[i], 
                   foldid = fold_id)
tabla_de_ajustes_2$mse_min[i] <- fit$cvm[
  fit$lambda == fit$lambda.min]

tabla_de_ajustes_2$mse_1se[i] <- fit$cvm[
  fit$lambda == fit$lambda.1se]

  tabla_de_ajustes_2$lambda_min[i] <- fit$lambda.min
  tabla_de_ajustes_2$lambda_1se[i] <- fit$lambda.1se
}

# Resultado 

kableExtra::kable(tabla_de_ajustes_2)
```

A continuación se representa gráficamente el error medio, junto con un intervalo de más menos una desviación típica, para cada nivel de alpha

```{r}
tabla_de_ajustes_2 %>%
  # Calculo de la desviacion tipica mediante la diferencia de los valores
  # extraidos del modelo
  mutate(se = mse_1se - mse_min) %>%
  
  # Grafico de linea, error cuadratico minimo en funcion de alpha
  ggplot(aes(alpha, mse_min)) +
  geom_line(size = 1.5, color = "red") +
  
  # Función para graficar el intervalo
  geom_ribbon(aes(ymax = mse_min + se, # limite superior del intervalo 
                  ymin = mse_min - se), # limite inferior del intervalo
              alpha = .25) +
  
  labs(title = "Error medio cuadrado minimo ± una desviación típica",
       x = "Nivel de alpha",
       y = "Mínimo error cuadrático medio") +
  theme_minimal()
```

Localizo el mínimo

```{r}
tabla_de_ajustes_2 %>%
  filter(mse_min == min(mse_min))
```

Nuevamente, el valor de alpha es 1. Realizo las predicciones con este modelo y comparo con las metricas anteriores.

```{r mejor modelo 2}
mejor_modelo_2 <- cv.glmnet(nba_train_x_2, 
                            nba_train_y_2, 
                            alpha = 1.0)

min(mejor_modelo$cvm)
min(mejor_modelo_2$cvm) 
```

Sobre los datos de entrenamiento, el modelo es ligeramente peor

```{r prediccion 2}
prediccion_2 <- predict(mejor_modelo_2, 
                      s = mejor_modelo_2$lambda.min, 
                      # el argumento "s"  determina el nivel
                      # del hiperparámetro lambda
                      nba_test_x_2)

# Comparo errores de prediccion

# Primer modelo (antes de meter el draft como dummy)
error_medio_primer_modelo <- mean((nba_test_y - prediccion)^2) 

# Segundo modelo: draft como dummy y eliminacion de outliers
error_medio_segundo_modelo <- mean((nba_test_y_2 - prediccion_2)^2) 
                              

# Desviaciones de los errores de los modelos 
desviacion_error_primer_modelo <- sd((nba_test_y - prediccion)^2) 
desviacion_error_segundo_modelo <- sd((nba_test_y_2 - prediccion_2)^2) 
```

Comparo los modelos

```{r comparacion error medio}
error_medio_primer_modelo
error_medio_segundo_modelo
```

El error medio es menor en el segundo modelo

```{r comparacion sd error}
desviacion_error_primer_modelo
desviacion_error_segundo_modelo
```

También presenta menor desviacion en los errores. No obstante, para comparar las desviaciones se calcula el coeficiente de desviación de Pearson

```{r}
desviacion_error_primer_modelo / error_medio_primer_modelo
desviacion_error_segundo_modelo / error_medio_segundo_modelo
```

Como se puede observar, el primer modelo posee una menor desviación de erorr en términos relativos a su error medio. En terminos de error medio, es cierto que el segundo modelo mejora, puesto que el error medio disminuye. Sin embargo, esta disminución no es directamente atribuíble a la creación de la variable dummy para el grupo de draft, puesto que también se han eliminado valores extremos de la muestra, y dichos valores se incluían en las estimaciones del primer modelo. Este hecho complica la comparación entre ambos modelos, puesto que no han sido evaluados exactamente con los mismos datos.  
  
    
      
        
          
          
